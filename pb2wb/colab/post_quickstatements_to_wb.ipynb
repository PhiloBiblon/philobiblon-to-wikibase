{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "lAxWMP15ZofD"
      },
      "outputs": [],
      "source": [
        "from google.colab import auth\n",
        "from googleapiclient.discovery import build\n",
        "import os\n",
        "import subprocess\n",
        "import time\n",
        "import datetime\n",
        "import json\n",
        "import io\n",
        "from googleapiclient.http import MediaIoBaseDownload"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "uK99N4bLZ1__"
      },
      "outputs": [],
      "source": [
        "auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "xic-_snBZ5NL"
      },
      "outputs": [],
      "source": [
        "service = build('drive', 'v3')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "NaT5r5mnxxSP"
      },
      "outputs": [],
      "source": [
        "SPLIT_FILES_SOURCE = {'BETA': '187KTNwJ2LZXf5d8WAFO1qnP6g8Yqderw',\n",
        "                      'BITECA': '',\n",
        "                      'BITAGAP': ''}\n",
        "\n",
        "SPLIT_FILES_PROCESSED= {'BETA': '1lc-XTCm9lSAfO6xIxxQ5K_4LzHhj3nPl',\n",
        "                           'BITECA': '',\n",
        "                           'BITAGAP': ''}\n",
        "WB_CONFIGS = {\n",
        "    'pb.cloud': {\n",
        "        'MEDIAWIKI_API_URL': 'https://pbsandbox.wikibase.cloud/qs/api.php',\n",
        "        'WB_USER': 'pb.cloud.user',\n",
        "        'WB_PASSWORD': 'pb.cloud.password',\n",
        "        'WB_TOKEN': 'pb.cloud.token'\n",
        "    },\n",
        "    'pb.cog': {\n",
        "        'MEDIAWIKI_API_URL': \"https://philobiblon.cog.berkeley.edu/qs/api.php\",\n",
        "        'WB_USER': 'pb.cog.user',\n",
        "        'WB_PASSWORD': 'pb.cog.password',\n",
        "        'WB_TOKEN': 'pb.cog.token',\n",
        "    },\n",
        "        'factgrid': {\n",
        "        'MEDIAWIKI_API_URL': \"https://database.factgrid.de/qs/api.php\",\n",
        "        'WB_USER': 'factgrid.user',\n",
        "        'WB_PASSWORD': 'factgrid.password',\n",
        "        'WB_TOKEN': 'factgrid.token',\n",
        "    }\n",
        "}\n",
        "\n",
        "# Manually update bibliography, table and instance that is to be updated\n",
        "bibliography = 'BETA' # BETA BITECA BITAGAP\n",
        "table = 'subject' # 'geography' 'analytic' 'library' 'ms_ed' 'biographies' 'copies' 'institutions' 'subject' 'uniform_title'\n",
        "instance = \"pb.cog\" # pb.cloud pb.cog factgrid\n",
        "batch_id = ''\n",
        "start_time = time.time()\n",
        "elapsed_time = 0\n",
        "max_seconds = 36000\n",
        "complete_status = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "iFun94tv9TTp"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "URL = WB_CONFIGS[instance]['MEDIAWIKI_API_URL']\n",
        "WB_USER = userdata.get(WB_CONFIGS[instance]['WB_USER'])\n",
        "WB_PASSWORD = userdata.get(WB_CONFIGS[instance]['WB_PASSWORD'])\n",
        "WB_TOKEN = userdata.get(WB_CONFIGS[instance]['WB_TOKEN'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ROJUV1wB8cEQ"
      },
      "outputs": [],
      "source": [
        "def time_check():\n",
        "    elapsed_time = time.time() - start_time\n",
        "    print(f\"Elapsed time: {elapsed_time} seconds\")\n",
        "    return elapsed_time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "eeJGaYdvlDQy"
      },
      "outputs": [],
      "source": [
        "def get_batch_status(batch_id):\n",
        "    batch_status_command = f\"curl {URL} -d action=get_batch_info -d batch={batch_id}\"\n",
        "    batch_status = subprocess.run(batch_status_command, capture_output=True, text=True, shell=True)\n",
        "    try:\n",
        "        data = json.loads(batch_status.stdout)\n",
        "        batch_status = data[\"data\"][str(batch_id)][\"batch\"][\"status\"]\n",
        "    except json.JSONDecodeError:\n",
        "        print(\"Error parsing JSON output:\", batch_status.stdout)\n",
        "    try:\n",
        "        error_count = data[\"data\"][str(batch_id)][\"commands\"]['ERROR']\n",
        "    except:\n",
        "        error_count = 0\n",
        "    return batch_status, error_count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "k0tPgYSQzTpy"
      },
      "outputs": [],
      "source": [
        "def move_file(source_id, destination_id, file_name, file_id):\n",
        "    file = service.files().get(fileId=file_id, fields='parents').execute()\n",
        "    previous_parents = \",\".join(file.get('parents'))\n",
        "    file = service.files().update(fileId=file_id,\n",
        "                                  addParents=destination_id,\n",
        "                                  removeParents=previous_parents,\n",
        "                                  fields='id, parents').execute()\n",
        "\n",
        "    print(f\"File '{file_name}' moved to folder with ID '{destination_id}'.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AdmASJlTfZJV",
        "outputId": "5d5437b3-1dc7-4612-86a2-0b73d8601d94"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Items:\n",
            "split_beta_subject_qs_0.qs (193RiZ5jlBNhCrwiB-t_fZwyJbh1QYDiH)\n",
            "Split Files Done (1lc-XTCm9lSAfO6xIxxQ5K_4LzHhj3nPl)\n",
            "[{'id': '193RiZ5jlBNhCrwiB-t_fZwyJbh1QYDiH', 'name': 'split_beta_subject_qs_0.qs'}]\n",
            "List of all files to be processed: ['split_beta_subject_qs_0.qs']\n",
            "Elapsed time: 1.9307582378387451 seconds\n",
            "split_beta_subject_qs_0.qs (193RiZ5jlBNhCrwiB-t_fZwyJbh1QYDiH)\n",
            "Downloading file: split_beta_subject_qs_0.qs\n",
            "Download 100%.\n",
            "File 'split_beta_subject_qs_0.qs' downloaded successfully.\n",
            "Batch ID: 57\n",
            "Batch import 57 still running, sleeping for 10 minutes\n",
            "Checking batch status\n",
            "Batch import 57 still running, sleeping for 10 minutes\n",
            "Checking batch status\n",
            "Batch import 57 still running, sleeping for 10 minutes\n",
            "Checking batch status\n",
            "Batch import 57 still running, sleeping for 10 minutes\n",
            "Checking batch status\n",
            "Batch import 57 still running, sleeping for 10 minutes\n",
            "Checking batch status\n",
            "Batch import 57 still running, sleeping for 10 minutes\n",
            "Checking batch status\n",
            "Batch import 57 still running, sleeping for 10 minutes\n",
            "Checking batch status\n",
            "Batch import 57 complete with status DONE\n",
            "Batch 57 had 32 errors\n",
            "File 'split_beta_subject_qs_0.qs' moved to folder with ID '1lc-XTCm9lSAfO6xIxxQ5K_4LzHhj3nPl'.\n",
            "Elapsed time: 4227.300355672836 seconds\n",
            "All files processed.  Completed in: 4227.300355672836 seconds\n"
          ]
        }
      ],
      "source": [
        "path_id = SPLIT_FILES_SOURCE[str(bibliography)]\n",
        "destination_id = SPLIT_FILES_PROCESSED[str(bibliography)]\n",
        "\n",
        "# Check for files in source directory\n",
        "results = service.files().list(q=f\"'{path_id}' in parents and trashed=false\", pageSize=1000, fields=\"nextPageToken, files(id, name)\").execute()\n",
        "items = results.get('files', [])\n",
        "if not items:\n",
        "    print('No items found.')\n",
        "else:\n",
        "    print('Items:')\n",
        "    for item in items:\n",
        "        print(u'{0} ({1})'.format(item['name'], item['id']))\n",
        "\n",
        "item_dict = [item for item in items if isinstance(item, dict)][0]\n",
        "table_items = [item for item in items if item['name'].endswith('.qs')]\n",
        "print(table_items)\n",
        "\n",
        "# Sort table items by split number\n",
        "table_items.sort(key=lambda x: int(x['name'].split('_')[4].split('.')[0]) if len(x['name'].split('_')) >= 4 else 0, reverse=False)\n",
        "names = [item['name'] for item in table_items]\n",
        "print(f'List of all files to be processed: {names}')\n",
        "\n",
        "# Loop through sorted items and process\n",
        "elapsed_time = time_check() # Get elapsed time so far to start\n",
        "while elapsed_time < max_seconds and not complete_status:\n",
        "    for table_item in table_items:\n",
        "        date = datetime.datetime.now().strftime(\"%Y%m%d_%H%M\")\n",
        "        batchname = f'{bibliography}_{table}_{date}'\n",
        "        print(u'{0} ({1})'.format(table_item['name'], table_item['id']))\n",
        "        file_id = table_item['id']\n",
        "        file_name = table_item['name']\n",
        "        # Download the file\n",
        "        print(f'Downloading file: {file_name}')\n",
        "        request = service.files().get_media(fileId=file_id)\n",
        "        fh = io.BytesIO()\n",
        "        downloader = MediaIoBaseDownload(fh, request)\n",
        "        done = False\n",
        "        while done is False:\n",
        "            status, done = downloader.next_chunk()\n",
        "            print(\"Download %d%%.\" % int(status.progress() * 100))\n",
        "\n",
        "        # Save the file to your Colab environment\n",
        "        with open(file_name, 'wb') as f:\n",
        "            f.write(fh.getbuffer())\n",
        "            print(f\"File '{file_name}' downloaded successfully.\")\n",
        "\n",
        "        # Run curl command submitting batch\n",
        "        curl_command = f'curl {URL} -d action=import -d submit=1 -d format=v1 -d username={WB_USER} -d batchname={batchname} --data-raw token=\\'{WB_TOKEN}\\' --data-urlencode data@{file_name}'\n",
        "        post_qs = subprocess.run(curl_command, capture_output=True, text=True, shell=True)\n",
        "        time.sleep(10) # Wait for batch to initiate\n",
        "\n",
        "        # move qs file to completed folder after submitted batch\n",
        "        move_file(path_id, destination_id, file_name, file_id)\n",
        "\n",
        "        if post_qs.returncode != 0:\n",
        "            print(\"Error executing curl command:\", post_qs.stderr)\n",
        "            exit(1)\n",
        "        try:\n",
        "            data = json.loads(post_qs.stdout)\n",
        "            batch_id = data[\"batch_id\"]\n",
        "        except json.JSONDecodeError:\n",
        "            print(f\"Error parsing JSON output for {batch_id}:\", post_qs.stdout)\n",
        "            continue\n",
        "        print(f\"Batch ID: {batch_id}\")\n",
        "        status = get_batch_status(batch_id)\n",
        "        while status != \"DONE\":\n",
        "            print(f'Batch import {batch_id} still running, sleeping for 10 minutes')\n",
        "            time.sleep(600)\n",
        "            print(\"Checking batch status\")\n",
        "            status, error_count = get_batch_status(batch_id)\n",
        "        print(f'Batch import {batch_id} complete with status {status}')\n",
        "        print(f'Batch {batch_id} had {error_count} errors')\n",
        "\n",
        "        # update elapsed time\n",
        "        elapsed_time = time_check()\n",
        "\n",
        "    complete_status = True\n",
        "\n",
        "print(f'All files processed.  Completed in: {elapsed_time} seconds')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}