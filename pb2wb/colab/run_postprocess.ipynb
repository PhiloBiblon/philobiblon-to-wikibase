{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Z5jHwjWfXMUQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4bc82f29-2f69-468d-ec31-5b3583ecda89"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authenticated\n",
            "Cloning into 'philobiblon-to-wikibase'...\n",
            "remote: Enumerating objects: 1214, done.\u001b[K\n",
            "remote: Counting objects: 100% (125/125), done.\u001b[K\n",
            "remote: Compressing objects: 100% (88/88), done.\u001b[K\n",
            "remote: Total 1214 (delta 62), reused 64 (delta 35), pack-reused 1089 (from 1)\u001b[K\n",
            "Receiving objects: 100% (1214/1214), 2.90 MiB | 28.24 MiB/s, done.\n",
            "Resolving deltas: 100% (708/708), done.\n"
          ]
        }
      ],
      "source": [
        "# !apt-get install git\n",
        "\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "print('Authenticated')\n",
        "\n",
        "import os\n",
        "!git clone https://github.com/PhiloBiblon/philobiblon-to-wikibase.git\n",
        "os.chdir('philobiblon-to-wikibase/pb2wb')\n",
        "\n",
        "from googleapiclient.discovery import build\n",
        "from googleapiclient.http import MediaIoBaseDownload\n",
        "import io\n",
        "from postprocess.postprocessor.generic import GenericPostprocessor\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "AyYpbgyjXidj"
      },
      "outputs": [],
      "source": [
        "service = build('drive', 'v3')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "6ezmirX3Xlj1"
      },
      "outputs": [],
      "source": [
        "# Set variables for folder id's, bib, tables and force statements\n",
        "\n",
        "OR_FILES_SOURCE = {'beta': '115pNT9ue480HAr996XbGRwWCLHFJK_V_',\n",
        "                   'biteca': '',\n",
        "                   'bitagap': ''}\n",
        "\n",
        "POST_FILES_DESTINATION = {'beta': '1efJDT_HJoIsrRBw1bySuIke6n3xaSTyt',\n",
        "                          'biteca': '',\n",
        "                          'bitagap': ''}\n",
        "\n",
        "# Set bibliography and tables to be post processed\n",
        "bibliography = ['beta'] #['beta', 'bitagap', 'biteca']\n",
        "tablenames = ['subject', 'biography'] #['uniform_title','analytic', 'biography', 'library', 'copies', 'ms_ed', 'institutions', 'geography', 'bibliography', 'subject']\n",
        "force_new_statements = True\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def find_file_id(folder_id, table):\n",
        "    query = f\"'{folder_id}' in parents and not mimeType='application/vnd.google-apps.folder'\"\n",
        "    results = service.files().list(q=query,fields=\"nextPageToken, files(id, name)\").execute()\n",
        "    file_name = [item['name'] for item in results['files'] if item['name'].endswith('.qs') and table in item['name']]\n",
        "    file_id = [item['id'] for item in results['files'] if item['name'].endswith('.qs') and table in item['name']]\n",
        "    if len(file_id) > 0:\n",
        "        return file_name[0], file_id[0]"
      ],
      "metadata": {
        "id": "FtAz1VVCInQX"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_folders(bib):\n",
        "  directory_path = f\"data/post/{bib}\"\n",
        "  if not os.path.exists(directory_path):\n",
        "    os.makedirs(directory_path)\n",
        "    print(f\"Directory '{directory_path}' created successfully.\")\n",
        "  else:\n",
        "    print(f\"Directory '{directory_path}' already exists.\")\n",
        "  return directory_path"
      ],
      "metadata": {
        "id": "AKesD_IhWLmC"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def download_file(file_name, file_id):\n",
        "    # Download the file\n",
        "    if len(file_id) > 0: # Check if file_id list contains any elements\n",
        "        print(f'Downloading file: {file_name} with id: {file_id}')\n",
        "        request = service.files().get_media(fileId=file_id)\n",
        "        fh = io.BytesIO()\n",
        "        downloader = MediaIoBaseDownload(fh, request)\n",
        "        done = False\n",
        "        while done is False:\n",
        "            status, done = downloader.next_chunk()\n",
        "            print(\"Download %d%%.\" % int(status.progress() * 100))\n",
        "    else:\n",
        "        print(f'No file found for {file_name}') # Handle the case of an empty file_id list\n",
        "\n",
        "    # Get the current working directory\n",
        "    cwd = os.getcwd()\n",
        "\n",
        "    # Construct the full path to the downloaded file\n",
        "    file_path = os.path.join(cwd, file_name)\n",
        "\n",
        "    # Save the downloaded file to the current working directory\n",
        "    with open(file_path, 'wb') as f:\n",
        "        fh.seek(0)\n",
        "        f.write(fh.read())\n",
        "\n",
        "    print(f'File downloaded to: {file_path}')"
      ],
      "metadata": {
        "id": "RH_r-D5gGrB9"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "k0tPgYSQzTpy"
      },
      "outputs": [],
      "source": [
        "def move_file(destination_id, file_name, file_id):\n",
        "    results = service.files().list(q=f\"name='{file_name}'\", fields=\"nextPageToken, files(id, name)\").execute()\n",
        "\n",
        "    # Find the file ID\n",
        "    for file in results.get('files', []):\n",
        "      print(file)\n",
        "      if file['name'] == f'{file_name}':\n",
        "        file_id = file['id']\n",
        "        break\n",
        "\n",
        "    # Get the metadata of the file to be copied\n",
        "    file_metadata = service.files().get(fileId=file_id).execute()\n",
        "\n",
        "    # Create a new file object with the desired destination folder\n",
        "    new_file_metadata = {\n",
        "        'name': file_metadata['name'],\n",
        "        'parents': [destination_id]\n",
        "    }\n",
        "\n",
        "    # Copy the file\n",
        "    copied_file = service.files().copy(fileId=file_id, body=new_file_metadata).execute()\n",
        "\n",
        "    print(f'File {file_name} copied successfully! New file ID:', copied_file['id'])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for bib in bibliography:\n",
        "  print(f'Processing for {bib} bibliography')\n",
        "  directory_path = create_folders(bib)\n",
        "  for item in tablenames:\n",
        "    print(f'Starting processing {item} table')\n",
        "    folder_id = OR_FILES_SOURCE[bib]\n",
        "    post_folder_id = POST_FILES_DESTINATION[bib]\n",
        "\n",
        "    try:\n",
        "      file_name, file_id = find_file_id(folder_id, item)\n",
        "    except:\n",
        "      print(f'No file found for {item}')\n",
        "      continue\n",
        "\n",
        "    download_file(file_name, file_id)\n",
        "    GenericPostprocessor().postprocess(file_name, directory_path, force_new_statements)\n",
        "    print(f'postprocess complete for {item}')\n",
        "    print('................................')\n",
        "\n",
        "    # Move processed file to Drive\n",
        "    move_file(post_folder_id, directory_path + '/' + file_name, file_id)\n",
        "\n",
        "  print('Post processing complete')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ONV5_ETMQmHj",
        "outputId": "a76038b0-231a-4b2a-e2ab-30ec2fbe8207"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing for beta bibliography\n",
            "Directory 'data/post/beta' created successfully.\n",
            "Starting processing subject table\n",
            "Downloading file: beta_subject.qs with id: 1YLRQFJPVJCZ3WnaBGDeKc1cmJXoJXv0m\n",
            "Download 100%.\n",
            "File downloaded to: /content/philobiblon-to-wikibase/pb2wb/beta_subject.qs\n",
            "postprocess complete for subject\n",
            "................................\n",
            "File data/post/beta/beta_subject.qs copied successfully! New file ID: 1qcgLyXhbAXLQDAqAqEm8jXgFQBFgnD2d\n",
            "Starting processing biography table\n",
            "Downloading file: beta_biography.qs with id: 1fvwZJFMzwdn1_vvRwxUcloV_ayVgvGI-\n",
            "Download 100%.\n",
            "File downloaded to: /content/philobiblon-to-wikibase/pb2wb/beta_biography.qs\n",
            "postprocess complete for biography\n",
            "................................\n",
            "File data/post/beta/beta_biography.qs copied successfully! New file ID: 1otxrZqMBEJdKzztAKWLwIeXF0-FRWJ9y\n",
            "Post processing complete\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}