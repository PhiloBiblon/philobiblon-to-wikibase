{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOWdI9FTBP/8B9fpllyI3Fj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PhiloBiblon/philobiblon-to-wikibase/blob/master/pb2wb/colab/qs_file_splitter.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9WhrCtiLAGS4",
        "outputId": "494f2add-83ec-4fdb-c40e-6fbdb3fd6c3f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authenticated\n"
          ]
        }
      ],
      "source": [
        "# Script to break up quickstatement files into managable chunks for importing into factgrid\n",
        "import io\n",
        "import os\n",
        "from google.colab import auth\n",
        "from googleapiclient.discovery import build\n",
        "from googleapiclient.http import MediaIoBaseDownload\n",
        "from googleapiclient.http import MediaFileUpload\n",
        "\n",
        "# auth user\n",
        "auth.authenticate_user()\n",
        "print('Authenticated')\n",
        "\n",
        "service = build('drive', 'v3')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set variables for folder id's, bib, tables and force statements\n",
        "\n",
        "QS_FILES_SOURCE = {'beta': '1efJDT_HJoIsrRBw1bySuIke6n3xaSTyt',\n",
        "                   'biteca': '',\n",
        "                   'bitagap': ''}\n",
        "\n",
        "SPLIT_FILES_STAGING = {'beta': '187KTNwJ2LZXf5d8WAFO1qnP6g8Yqderw',\n",
        "                          'biteca': '',\n",
        "                          'bitagap': ''}\n"
      ],
      "metadata": {
        "id": "YE_b5x-nBQuQ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def find_file_id(folder_id, table):\n",
        "    query = f\"'{folder_id}' in parents and not mimeType='application/vnd.google-apps.folder'\"\n",
        "    results = service.files().list(q=query,fields=\"nextPageToken, files(id, name)\").execute()\n",
        "    file_name = [item['name'] for item in results['files'] if item['name'].endswith('.qs') and table in item['name']]\n",
        "    file_id = [item['id'] for item in results['files'] if item['name'].endswith('.qs') and table in item['name']]\n",
        "    if len(file_id) > 0:\n",
        "        return file_name[0], file_id[0]"
      ],
      "metadata": {
        "id": "mrxNoOh7AnbV"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def download_file(file_name, file_id):\n",
        "    # Download the file\n",
        "    if len(file_id) > 0: # Check if file_id list contains any elements\n",
        "        print(f'Downloading file: {file_name} with id: {file_id}')\n",
        "        request = service.files().get_media(fileId=file_id)\n",
        "        fh = io.BytesIO()\n",
        "        downloader = MediaIoBaseDownload(fh, request)\n",
        "        done = False\n",
        "        while done is False:\n",
        "            status, done = downloader.next_chunk()\n",
        "            print(\"Download %d%%.\" % int(status.progress() * 100))\n",
        "    else:\n",
        "        print(f'No file found for {file_name}') # Handle the case of an empty file_id list\n",
        "\n",
        "    # Get the current working directory\n",
        "    cwd = os.getcwd()\n",
        "\n",
        "    # Construct the full path to the downloaded file\n",
        "    file_path = os.path.join(cwd, file_name)\n",
        "\n",
        "    # Save the downloaded file to the current working directory\n",
        "    with open(file_path, 'wb') as f:\n",
        "        fh.seek(0)\n",
        "        f.write(fh.read())\n",
        "\n",
        "    print(f'File downloaded to: {file_path}')"
      ],
      "metadata": {
        "id": "VYkD6EWmArkD"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def move_file(destination_id, file_name):\n",
        "    file_metadata = {'name': os.path.basename(file_name)}\n",
        "    media = MediaFileUpload(file_name)  # Adjust mimetype if needed\n",
        "    file = service.files().create(body=file_metadata, media_body=media, fields='id').execute()\n",
        "    file_id = file['id']\n",
        "\n",
        "    # Move the uploaded file to the desired folder\n",
        "    file = service.files().get(fileId=file_id, fields='parents').execute()\n",
        "    previous_parents = \",\".join(file.get('parents'))\n",
        "    file = service.files().update(fileId=file_id,\n",
        "                                  addParents=destination_id,\n",
        "                                  removeParents=previous_parents,\n",
        "                                  fields='id, parents').execute()\n",
        "\n",
        "    print(f'File {file_name} copied successfully! File ID: {file_id}')"
      ],
      "metadata": {
        "id": "1WzIBqi-C-Fv"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def find_unique_items(unique_items, update_file):\n",
        "    # Find all other rows that start with the same 'Q' item\n",
        "    print(update_file)\n",
        "    updated_lines = []\n",
        "    for line in original_lines:\n",
        "        if line.startswith('Q'):\n",
        "            item = line.split('\\t')[0]\n",
        "            if item in unique_items:\n",
        "                updated_lines.append(line)\n",
        "\n",
        "    # Write the updated quickstatements file\n",
        "    with open(update_file, 'w') as file:\n",
        "        file.writelines(updated_lines)\n",
        "        print(f'File {update_file} created successfully!')\n",
        "\n",
        "    # Move the updated file to the staging folder\n",
        "    move_file(SPLIT_FILES_STAGING[bib], update_file)"
      ],
      "metadata": {
        "id": "2DOqTggTDCh5"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Table to be split\n",
        "table = 'library' #['uniform_title','analytic', 'biography', 'library', 'copies', 'ms_ed', 'institutions', 'geography', 'bibliography', 'subject']\n",
        "bib = 'beta' #['beta', 'bitagap', 'biteca']\n",
        "\n",
        "# Find and download files to be split\n",
        "file_name, file_id = find_file_id(QS_FILES_SOURCE[bib], table)\n",
        "download_file(file_name, file_id)\n",
        "\n",
        "# Read the original quickstatements file\n",
        "with open(f'{bib}_{table}.qs', 'r') as file:\n",
        "    original_lines = file.readlines()\n",
        "\n",
        "# Lets find the first 250 unique items where the rows start with 'Q'\n",
        "unique_items = set()\n",
        "file_number = 0\n",
        "last_item = None\n",
        "\n",
        "'''for line in original_lines:\n",
        "    update_file = f'split_{bib}_{table}_qs' + \"_\" + str(file_number) + \".qs\"\n",
        "    if line.startswith('Q'):\n",
        "        item = line.split('\\t')[0]\n",
        "        unique_items.add(item)\n",
        "        if len(unique_items) == 250:\n",
        "            # Check for duplication after adding the first item\n",
        "            if last_item in unique_items:\n",
        "                print(f'Last item {last_item} is in the set')\n",
        "                unique_items.remove(last_item)\n",
        "\n",
        "            find_unique_items(unique_items, update_file)\n",
        "            file_number += 1\n",
        "\n",
        "            # Set last_item after clearing the previous set\n",
        "            unique_items.clear()\n",
        "            last_item = item\n",
        "        else:\n",
        "            continue'''\n",
        "\n",
        "for line in original_lines:\n",
        "    update_file = f'split_{bib}_{table}_qs' + \"_\" + str(file_number) + \".qs\"\n",
        "    if line.startswith('Q'):\n",
        "        item = line.split('\\t')[0]\n",
        "        unique_items.add(item)\n",
        "        if len(unique_items) == 250:\n",
        "            # Check for duplication after adding the first item\n",
        "            if last_item in unique_items:\n",
        "                print(f'Last item {last_item} is in the set')\n",
        "                unique_items.remove(last_item)\n",
        "\n",
        "            find_unique_items(unique_items, update_file)\n",
        "            file_number += 1\n",
        "\n",
        "            # Set last_item after clearing the previous set\n",
        "            unique_items.clear()\n",
        "            last_item = item\n",
        "        else:\n",
        "            continue\n",
        "\n",
        "# If we've processed all lines and there are less than 250 unique items left, lets include them\n",
        "find_unique_items(unique_items, update_file)\n",
        "\n",
        "\n",
        "print(f'File splits compeleted successfully')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hIsWFt8jDQUD",
        "outputId": "305347cb-89e4-4eb4-bafb-7d18f9d7e821"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading file: beta_library.qs with id: 1HvK_v-phEfC_6_gEP9zItYoRW2ZA7hvu\n",
            "Download 100%.\n",
            "File downloaded to: /content/beta_library.qs\n",
            "split_beta_library_qs_0.qs\n",
            "File split_beta_library_qs_0.qs created successfully!\n",
            "File split_beta_library_qs_0.qs copied successfully! File ID: 19tK8D8W_wtddrXJ0v1_Shp8G4B5M-YmU\n",
            "Last item Q37027 is in the set\n",
            "split_beta_library_qs_1.qs\n",
            "File split_beta_library_qs_1.qs created successfully!\n",
            "File split_beta_library_qs_1.qs copied successfully! File ID: 1s-cuWtwFx3beBEb-nTZxO2rjTxDRk5ka\n",
            "split_beta_library_qs_2.qs\n",
            "File split_beta_library_qs_2.qs created successfully!\n",
            "File split_beta_library_qs_2.qs copied successfully! File ID: 1AxFkGBV28MqgSxnzXGp5jvkk7vocCxvK\n",
            "File splits compeleted successfully\n"
          ]
        }
      ]
    }
  ]
}