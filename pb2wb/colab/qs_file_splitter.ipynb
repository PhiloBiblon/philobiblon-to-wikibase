{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMfAgh4YDvUYuleAJwCFUx9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PhiloBiblon/philobiblon-to-wikibase/blob/master/pb2wb/colab/qs_file_splitter.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9WhrCtiLAGS4",
        "outputId": "494f2add-83ec-4fdb-c40e-6fbdb3fd6c3f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authenticated\n"
          ]
        }
      ],
      "source": [
        "# Script to break up quickstatement files into managable chunks for importing into factgrid\n",
        "import io\n",
        "import os\n",
        "from google.colab import auth\n",
        "from googleapiclient.discovery import build\n",
        "from googleapiclient.http import MediaIoBaseDownload\n",
        "from googleapiclient.http import MediaFileUpload\n",
        "\n",
        "# auth user\n",
        "auth.authenticate_user()\n",
        "print('Authenticated')\n",
        "\n",
        "service = build('drive', 'v3')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set variables for folder id's, bib, tables and force statements\n",
        "\n",
        "QS_FILES_SOURCE = {'beta': '1efJDT_HJoIsrRBw1bySuIke6n3xaSTyt',\n",
        "                   'biteca': '',\n",
        "                   'bitagap': ''}\n",
        "\n",
        "SPLIT_FILES_STAGING = {'beta': '187KTNwJ2LZXf5d8WAFO1qnP6g8Yqderw',\n",
        "                          'biteca': '',\n",
        "                          'bitagap': ''}\n"
      ],
      "metadata": {
        "id": "YE_b5x-nBQuQ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def find_file_id(folder_id, table):\n",
        "    query = f\"'{folder_id}' in parents and not mimeType='application/vnd.google-apps.folder'\"\n",
        "    results = service.files().list(q=query,fields=\"nextPageToken, files(id, name)\").execute()\n",
        "    file_name = [item['name'] for item in results['files'] if item['name'].endswith('.qs') and table in item['name']]\n",
        "    file_id = [item['id'] for item in results['files'] if item['name'].endswith('.qs') and table in item['name']]\n",
        "    if len(file_id) > 0:\n",
        "        return file_name[0], file_id[0]"
      ],
      "metadata": {
        "id": "mrxNoOh7AnbV"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def download_file(file_name, file_id):\n",
        "    # Download the file\n",
        "    if len(file_id) > 0: # Check if file_id list contains any elements\n",
        "        print(f'Downloading file: {file_name} with id: {file_id}')\n",
        "        request = service.files().get_media(fileId=file_id)\n",
        "        fh = io.BytesIO()\n",
        "        downloader = MediaIoBaseDownload(fh, request)\n",
        "        done = False\n",
        "        while done is False:\n",
        "            status, done = downloader.next_chunk()\n",
        "            print(\"Download %d%%.\" % int(status.progress() * 100))\n",
        "    else:\n",
        "        print(f'No file found for {file_name}') # Handle the case of an empty file_id list\n",
        "\n",
        "    # Get the current working directory\n",
        "    cwd = os.getcwd()\n",
        "\n",
        "    # Construct the full path to the downloaded file\n",
        "    file_path = os.path.join(cwd, file_name)\n",
        "\n",
        "    # Save the downloaded file to the current working directory\n",
        "    with open(file_path, 'wb') as f:\n",
        "        fh.seek(0)\n",
        "        f.write(fh.read())\n",
        "\n",
        "    print(f'File downloaded to: {file_path}')"
      ],
      "metadata": {
        "id": "VYkD6EWmArkD"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def move_file(destination_id, file_name):\n",
        "    file_metadata = {'name': os.path.basename(file_name)}\n",
        "    media = MediaFileUpload(file_name)  # Adjust mimetype if needed\n",
        "    file = service.files().create(body=file_metadata, media_body=media, fields='id').execute()\n",
        "    file_id = file['id']\n",
        "\n",
        "    # Move the uploaded file to the desired folder\n",
        "    file = service.files().get(fileId=file_id, fields='parents').execute()\n",
        "    previous_parents = \",\".join(file.get('parents'))\n",
        "    file = service.files().update(fileId=file_id,\n",
        "                                  addParents=destination_id,\n",
        "                                  removeParents=previous_parents,\n",
        "                                  fields='id, parents').execute()\n",
        "\n",
        "    print(f'File {file_name} copied successfully! File ID: {file_id}')"
      ],
      "metadata": {
        "id": "1WzIBqi-C-Fv"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def find_unique_items(unique_items, update_file):\n",
        "    # Find all other rows that start with the same 'Q' item\n",
        "    print(update_file)\n",
        "    updated_lines = []\n",
        "    for line in original_lines:\n",
        "        if line.startswith('Q'):\n",
        "            item = line.split('\\t')[0]\n",
        "            if item in unique_items:\n",
        "                updated_lines.append(line)\n",
        "\n",
        "    # Write the updated quickstatements file\n",
        "    with open(update_file, 'w') as file:\n",
        "        file.writelines(updated_lines)\n",
        "        print(f'File {update_file} created successfully!')\n",
        "\n",
        "    # Move the updated file to the staging folder\n",
        "    move_file(SPLIT_FILES_STAGING[bib], update_file)"
      ],
      "metadata": {
        "id": "2DOqTggTDCh5"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Table to be split\n",
        "table = 'ms_ed' #['uniform_title','analytic', 'biography', 'library', 'copies', 'ms_ed', 'institutions', 'geography', 'bibliography', 'subject']\n",
        "bib = 'beta' #['beta', 'bitagap', 'biteca']\n",
        "\n",
        "# Find and download files to be split\n",
        "file_name, file_id = find_file_id(QS_FILES_SOURCE[bib], table)\n",
        "download_file(file_name, file_id)\n",
        "\n",
        "# Read the original quickstatements file\n",
        "with open(f'{bib}_{table}.qs', 'r') as file:\n",
        "    original_lines = file.readlines()\n",
        "\n",
        "# Lets find the first 250 unique items where the rows start with 'Q'\n",
        "unique_items = set()\n",
        "file_number = 0\n",
        "last_item = None\n",
        "\n",
        "for line in original_lines:\n",
        "    update_file = f'split_{bib}_{table}_qs' + \"_\" + str(file_number) + \".qs\"\n",
        "    if line.startswith('Q'):\n",
        "        item = line.split('\\t')[0]\n",
        "        unique_items.add(item)\n",
        "        if len(unique_items) == 250:\n",
        "            # Check for duplication after adding the first item\n",
        "            if last_item in unique_items:\n",
        "                print(f'Last item {last_item} is in the set')\n",
        "                unique_items.remove(last_item)\n",
        "\n",
        "            find_unique_items(unique_items, update_file)\n",
        "            file_number += 1\n",
        "\n",
        "            # Set last_item after clearing the previous set\n",
        "            unique_items.clear()\n",
        "            last_item = item\n",
        "        else:\n",
        "            continue\n",
        "\n",
        "# If we've processed all lines and there are less than 250 unique items left, lets include them after removing last item if there\n",
        "if last_item in unique_items:\n",
        "    print(f'Last item {last_item} is in the set')\n",
        "    unique_items.remove(last_item)\n",
        "find_unique_items(unique_items, update_file)\n",
        "\n",
        "\n",
        "print(f'File splits compeleted successfully')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hIsWFt8jDQUD",
        "outputId": "7ce82a97-e5d7-47d9-e197-502557e0303a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading file: beta_ms_ed.qs with id: 1wtajIZNhfo4yPCWHmYP_-gzTRfhWjYvx\n",
            "Download 100%.\n",
            "File downloaded to: /content/beta_ms_ed.qs\n",
            "split_beta_ms_ed_qs_0.qs\n",
            "File split_beta_ms_ed_qs_0.qs created successfully!\n",
            "File split_beta_ms_ed_qs_0.qs copied successfully! File ID: 1FqWT_Wj8ikobAaSuDD45Pn9Saem8_IuD\n",
            "Last item Q37937 is in the set\n",
            "split_beta_ms_ed_qs_1.qs\n",
            "File split_beta_ms_ed_qs_1.qs created successfully!\n",
            "File split_beta_ms_ed_qs_1.qs copied successfully! File ID: 1hmk7wuCLC6v898ofso5Cnwjz2KmjMidu\n",
            "Last item Q38186 is in the set\n",
            "split_beta_ms_ed_qs_2.qs\n",
            "File split_beta_ms_ed_qs_2.qs created successfully!\n",
            "File split_beta_ms_ed_qs_2.qs copied successfully! File ID: 1kqZWc6hAwtqhBl55qIuYLi3RpcXLqYie\n",
            "Last item Q38435 is in the set\n",
            "split_beta_ms_ed_qs_3.qs\n",
            "File split_beta_ms_ed_qs_3.qs created successfully!\n",
            "File split_beta_ms_ed_qs_3.qs copied successfully! File ID: 1xx6Ig-ljtdQFysqeG-bi0gZoyFi6n5-a\n",
            "Last item Q38684 is in the set\n",
            "split_beta_ms_ed_qs_4.qs\n",
            "File split_beta_ms_ed_qs_4.qs created successfully!\n",
            "File split_beta_ms_ed_qs_4.qs copied successfully! File ID: 1Wf86ijzmNQWYQIVVaiNt6X3arAXpUZcw\n",
            "Last item Q38933 is in the set\n",
            "split_beta_ms_ed_qs_5.qs\n",
            "File split_beta_ms_ed_qs_5.qs created successfully!\n",
            "File split_beta_ms_ed_qs_5.qs copied successfully! File ID: 1-7tXjc8bM5iJ7efU8ghzoVyCS73bJEia\n",
            "Last item Q39182 is in the set\n",
            "split_beta_ms_ed_qs_6.qs\n",
            "File split_beta_ms_ed_qs_6.qs created successfully!\n",
            "File split_beta_ms_ed_qs_6.qs copied successfully! File ID: 1BQ9dRPM6ZDyuCuObk-ErwKhdMpArW6YJ\n",
            "Last item Q39431 is in the set\n",
            "split_beta_ms_ed_qs_7.qs\n",
            "File split_beta_ms_ed_qs_7.qs created successfully!\n",
            "File split_beta_ms_ed_qs_7.qs copied successfully! File ID: 1YmN716S7R-C2UXlXl8vTryvKnI7BTJsK\n",
            "Last item Q39680 is in the set\n",
            "split_beta_ms_ed_qs_8.qs\n",
            "File split_beta_ms_ed_qs_8.qs created successfully!\n",
            "File split_beta_ms_ed_qs_8.qs copied successfully! File ID: 12ZxAoL5v1lakHlWznKMJm2LhjuFTL2HI\n",
            "Last item Q39929 is in the set\n",
            "split_beta_ms_ed_qs_9.qs\n",
            "File split_beta_ms_ed_qs_9.qs created successfully!\n",
            "File split_beta_ms_ed_qs_9.qs copied successfully! File ID: 13qLFdlP5CY8LDIm5lFN9OPyShko7luJW\n",
            "Last item Q40178 is in the set\n",
            "split_beta_ms_ed_qs_10.qs\n",
            "File split_beta_ms_ed_qs_10.qs created successfully!\n",
            "File split_beta_ms_ed_qs_10.qs copied successfully! File ID: 18mAvnNlYpWaPu234myS45Gzok5B127GJ\n",
            "Last item Q40427 is in the set\n",
            "split_beta_ms_ed_qs_11.qs\n",
            "File split_beta_ms_ed_qs_11.qs created successfully!\n",
            "File split_beta_ms_ed_qs_11.qs copied successfully! File ID: 1HbPx8lRGHGBG5eMEpK-EjqM9xPGQuQyn\n",
            "Last item Q40676 is in the set\n",
            "split_beta_ms_ed_qs_12.qs\n",
            "File split_beta_ms_ed_qs_12.qs created successfully!\n",
            "File split_beta_ms_ed_qs_12.qs copied successfully! File ID: 12CN-ozqqIQgAsMSS_qILxf4LcMG1UfDj\n",
            "Last item Q40925 is in the set\n",
            "split_beta_ms_ed_qs_13.qs\n",
            "File split_beta_ms_ed_qs_13.qs created successfully!\n",
            "File split_beta_ms_ed_qs_13.qs copied successfully! File ID: 1qireCGGT5svGtHXIlxmz9oQPGlUcF3z-\n",
            "Last item Q41174 is in the set\n",
            "split_beta_ms_ed_qs_14.qs\n",
            "File split_beta_ms_ed_qs_14.qs created successfully!\n",
            "File split_beta_ms_ed_qs_14.qs copied successfully! File ID: 1gLYT24bAMZB1bh4pmRN7bjWhvzwzN2rG\n",
            "Last item Q41423 is in the set\n",
            "split_beta_ms_ed_qs_15.qs\n",
            "File split_beta_ms_ed_qs_15.qs created successfully!\n",
            "File split_beta_ms_ed_qs_15.qs copied successfully! File ID: 1nCDIc24a1dPUM1wVtlLup1yck_m0LfCi\n",
            "Last item Q41672 is in the set\n",
            "split_beta_ms_ed_qs_16.qs\n",
            "File split_beta_ms_ed_qs_16.qs created successfully!\n",
            "File split_beta_ms_ed_qs_16.qs copied successfully! File ID: 1ZEPW-FZHcT1vg7QosKWDy0n11ZH7tDZd\n",
            "Last item Q41921 is in the set\n",
            "split_beta_ms_ed_qs_17.qs\n",
            "File split_beta_ms_ed_qs_17.qs created successfully!\n",
            "File split_beta_ms_ed_qs_17.qs copied successfully! File ID: 1ShLyZjKvagsZi9-Y7qWyLR0R_m2fbx0M\n",
            "Last item Q42170 is in the set\n",
            "split_beta_ms_ed_qs_18.qs\n",
            "File split_beta_ms_ed_qs_18.qs created successfully!\n",
            "File split_beta_ms_ed_qs_18.qs copied successfully! File ID: 1nOAYDq_iN5s-2guwP3zebF4mvp2nC5Tr\n",
            "Last item Q42419 is in the set\n",
            "split_beta_ms_ed_qs_19.qs\n",
            "File split_beta_ms_ed_qs_19.qs created successfully!\n",
            "File split_beta_ms_ed_qs_19.qs copied successfully! File ID: 16CJzZlE3ttHfTs4ItpM9UA_Ll9G-Skzc\n",
            "Last item Q42668 is in the set\n",
            "split_beta_ms_ed_qs_20.qs\n",
            "File split_beta_ms_ed_qs_20.qs created successfully!\n",
            "File split_beta_ms_ed_qs_20.qs copied successfully! File ID: 1GM-ggXE4O4IAtG8iZRRp5wBtuSj6euti\n",
            "Last item Q42917 is in the set\n",
            "split_beta_ms_ed_qs_21.qs\n",
            "File split_beta_ms_ed_qs_21.qs created successfully!\n",
            "File split_beta_ms_ed_qs_21.qs copied successfully! File ID: 1rLMjO_26pAUWN7ieQWyknt_aHaRl4J6x\n",
            "File splits compeleted successfully\n"
          ]
        }
      ]
    }
  ]
}